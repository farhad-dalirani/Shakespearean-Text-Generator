{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Attention Concept:\n",
        "\n",
        "1. Attention is a form of communication, where information is exchanged between tokens. The computation occurs through feed-forward operations after the attention mechanism.\n",
        "2. In the attention mechanism, each token in a sentence is considered as a node and is connected to the previous tokens as well as itself. For different problems, this directed graph may vary. Attention helps in finding a feature vector for each node by facilitating communication with other nodes.\n",
        "3. Self-attention involves using the same source for obtaining key, value, and query. On the other hand, cross-attention involves using two different sources for {key, value} and query.\n",
        "4. To effectively scale the network, it is necessary to incorporate residual connections and layer normalization. These techniques help maintain the integrity and stability of the network architecture.\n",
        "5. Multi-head attention is like group convolution. It results in better outcome and more stable training.\n",
        "6. For more detail see decoder part of Attention all you need paper."
      ],
      "metadata": {
        "id": "4djQocyS4K3p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "CANtiJTb7CM6"
      },
      "outputs": [],
      "source": [
        "# Libs\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "class Configuration:\n",
        "  # mini-batch size\n",
        "  batch_size = 64\n",
        "  # number of tokens in each data of the batch\n",
        "  block_size = 256\n",
        "  # lenght of embeding for each token\n",
        "  embd_size = 384\n",
        "  # number of head in multi-head attention\n",
        "  num_heads = 6\n",
        "  # Embeding size of each attention head\n",
        "  head_size = embd_size // num_heads\n",
        "  # number of attention blocks\n",
        "  num_attention_block=6\n",
        "  # training and evalution\n",
        "  number_iterations = 5000\n",
        "  learning_rate = 3e-4\n",
        "  dropout = 0.2\n",
        "  # if GPU is available use it\n",
        "  device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "  eval_interval = 500\n",
        "  eval_iters = 200\n",
        "  torch.manual_seed(1337)\n",
        "\n",
        "# Instance of Configuration class\n",
        "conf = Configuration()\n",
        "\n",
        "if conf.embd_size % conf.num_heads != 0:\n",
        "  raise ValueError('Embeding size should be dividable by number of heads.')\n",
        "print('Device: {}'.format(conf.device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7psQk97ux4E",
        "outputId": "00aa7d3f-c645-4539-8474-816d2ec97016"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "with open('sample_data/input.txt', 'r', encoding='utf-8') as f:\n",
        "  ds_text = f.read()"
      ],
      "metadata": {
        "id": "54BIHDZTGi35"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show part of data\n",
        "print(ds_text[:300])"
      ],
      "metadata": {
        "id": "XfQ6v0uwHRCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f823660c-41d8-4dc6-b328-832b726d3872"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique characters, in this code, characters are tokens, for better result\n",
        "# tools such as OpenAI tokenizer can be used.\n",
        "vocabolary = sorted(list(set(ds_text)))\n",
        "conf.vocabolary_size = len(vocabolary)\n",
        "\n",
        "print(conf.vocabolary_size)\n",
        "print(vocabolary)"
      ],
      "metadata": {
        "id": "w0EoIhAZHRGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985a17b2-6b7b-498f-e9d7-7fcab0d69fdc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert encode and decode data\n",
        "dic_vocab_idx = {vocabolary[i]: i for i in range(conf.vocabolary_size)}\n",
        "dic_idx_vocab = {i:vocabolary[i] for i in range(conf.vocabolary_size)}\n",
        "\n",
        "encode = lambda tx: [dic_vocab_idx[ch] for ch in tx]\n",
        "decode = lambda list_int: ''.join([dic_idx_vocab[id] for id in list_int])"
      ],
      "metadata": {
        "id": "gGuxzr75HRKa"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode('Hello There!'))\n",
        "print(decode(encode('Hello There!')))"
      ],
      "metadata": {
        "id": "anSPdyuWGnfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc3b128-f418-43f1-dad3-f0446b3387cb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 43, 50, 50, 53, 1, 32, 46, 43, 56, 43, 2]\n",
            "Hello There!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all text for integer\n",
        "ds_tensor = torch.tensor(encode(ds_text), dtype=torch.long)"
      ],
      "metadata": {
        "id": "XCjhBAFEWYgH"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds_tensor.type)\n",
        "print(ds_tensor.shape)"
      ],
      "metadata": {
        "id": "FHn8V_IEWYkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd52836-10c1-4b94-f851-80a8a6996c63"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method type of Tensor object at 0x7fc0adcad9e0>\n",
            "torch.Size([1115394])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split all data to train and validation\n",
        "n_split = int(len(ds_tensor) * 0.9)\n",
        "train_data = ds_tensor[:n_split]\n",
        "val_data = ds_tensor[n_split:]"
      ],
      "metadata": {
        "id": "r2_bM567WYn7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(val_data.shape)"
      ],
      "metadata": {
        "id": "HBCFyGD5WYqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360a3648-d3a1-4268-c5cd-568bdca3ca60"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1003854])\n",
            "torch.Size([111540])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a mini-batch\n",
        "def get_batch(split_name):\n",
        "  if split_name == 'train':\n",
        "    data = train_data\n",
        "  elif split_name == 'eval':\n",
        "    data = val_data\n",
        "  else:\n",
        "    raise ValueError('Split name is incorrect.')\n",
        "\n",
        "  idxs = torch.randint(low=0, high=len(data)-conf.block_size, size=(conf.batch_size,))\n",
        "  X = torch.stack([data[id:id+conf.block_size] for id in idxs])\n",
        "  y = torch.stack([data[id+1:id+conf.block_size+1] for id in idxs])\n",
        "  # Move data to device\n",
        "  X, y = X.to(conf.device), y.to(conf.device)\n",
        "  return X, y\n"
      ],
      "metadata": {
        "id": "xVgnPpPlc3Y0"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  \"\"\" Estimate train and eval loss.\"\"\"\n",
        "  evaluation = {'train':None, 'eval':None}\n",
        "  losses = {'train':[], 'eval':[]}\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "  # Estimate train and eval loss on whole data\n",
        "  # by calculating loss on a number of batches\n",
        "  for split in ['train', 'eval']:\n",
        "    for i in range(conf.eval_iters):\n",
        "      X, y = get_batch(split_name=split)\n",
        "      _, loss = model(X, y)\n",
        "      losses[split].append(loss.item())\n",
        "  evaluation['train'] = sum(losses['train']) / len(losses['train'])\n",
        "  evaluation['eval'] = sum(losses['eval']) / len(losses['eval'])\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "  return evaluation\n"
      ],
      "metadata": {
        "id": "7RQ4scVwKewv"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  \"\"\"One attention head.\"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Linear layers to generate key, value and query\n",
        "    self.key = nn.Linear(in_features=conf.embd_size, out_features=conf.head_size, bias=False)\n",
        "    self.value = nn.Linear(in_features=conf.embd_size, out_features=conf.head_size, bias=False)\n",
        "    self.query = nn.Linear(in_features=conf.embd_size, out_features=conf.head_size, bias=False)\n",
        "    # This matrix is used for masking. Tokens in text generation should not\n",
        "    # have access to future tokens\n",
        "    self.register_buffer(\n",
        "        'tril', torch.tril(torch.ones(conf.block_size, conf.block_size)))\n",
        "    self.dropout = nn.Dropout(conf.dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "\n",
        "    # Generate key, value, query\n",
        "    k = self.key(x) # (B, T, Head size)\n",
        "    v = self.value(x) # (B, T, Head size)\n",
        "    q = self.query(x) # (B, T, Head size)\n",
        "    # Compute attention scores (affinities)\n",
        "    wei = q @ k.transpose(-2, -1) * (C ** -0.5)\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "    wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "    wei = self.dropout(wei)\n",
        "    # Weighted aggregation of values\n",
        "    out = wei @ v # (B, T, Head size)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "451oEFMXcW1-"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\"Multihead attention\"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Put several head together\n",
        "    self.heads = nn.ModuleList([Head() for _ in range(conf.num_heads)])\n",
        "    self.projection = nn.Linear(conf.embd_size, conf.embd_size)\n",
        "    self.dropout = nn.Dropout(conf.dropout)\n",
        "  def forward(self, x):\n",
        "    x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "    x = self.projection(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "hx7h1qKj0_bZ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  \"\"\"MLP layet after each multi-head attention\"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(conf.embd_size, 4 * conf.embd_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * conf.embd_size, conf.embd_size),\n",
        "        nn.Dropout(conf.dropout)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "O3smuLMwEhXt"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "  \"\"\"\n",
        "  Communication (multi-head attention) followed by computation (MLP)\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer_norm_1 = nn.LayerNorm(conf.embd_size)\n",
        "    self.layer_norm_2 = nn.LayerNorm(conf.embd_size)\n",
        "    # Multi-head self-attention\n",
        "    self.sa_head = MultiHeadAttention()\n",
        "    # Feed-forward after multi-head attention\n",
        "    self.fd = FeedForward()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.sa_head(self.layer_norm_1(x))\n",
        "    x = x + self.fd(self.layer_norm_2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "ct3vDNKJGuvx"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionNeuralNetwork(nn.Module):\n",
        "  \"\"\"Language model constructed of attention blocks\"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Embeding table for each token\n",
        "    self.token_embeding_table = nn.Embedding(\n",
        "                                   num_embeddings=conf.vocabolary_size,\n",
        "                                   embedding_dim=conf.embd_size)\n",
        "    # Positional embeding for each position in the sequence. This is because\n",
        "    # tokens should have knowledge about their location in sequence\n",
        "    self.position_embeding_table = nn.Embedding(\n",
        "                                      num_embeddings=conf.block_size,\n",
        "                                      embedding_dim=conf.embd_size)\n",
        "\n",
        "    # Attention blocks\n",
        "    self.blocks = nn.Sequential(\n",
        "        *[AttentionBlock()\n",
        "          for _ in range(conf.num_attention_block)])\n",
        "    # Normalize\n",
        "    self.layer_norm = nn.LayerNorm(conf.embd_size)\n",
        "    # Last linear layer to increase output from embeding size to vocabolary size\n",
        "    self.lm_head = nn.Linear(conf.embd_size, conf.vocabolary_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    B, T = idx.shape\n",
        "    token_emb = self.token_embeding_table(idx) # (B, T, C_emb)\n",
        "    pos_emb = self.position_embeding_table(\n",
        "                      torch.arange(T, device=conf.device)) # (T, C_emb)\n",
        "    # add token embedings and positional embedings\n",
        "    x = token_emb + pos_emb # (B, T, C_emb)\n",
        "    x = self.blocks(x) # (B, T, C_emb)\n",
        "    x = self.layer_norm(x) # (B, T, C_emb)\n",
        "    logits = self.lm_head(x) # (B, T, C_vocab)\n",
        "\n",
        "    if targets is not None:\n",
        "      # Calculate cross entropy loss\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B * T, C)\n",
        "      targets = targets.view(B * T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    else:\n",
        "      loss = None\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    \"\"\"\n",
        "    This generate text\n",
        "    idx: (B, T tensor)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    for i in range(max_new_tokens):\n",
        "      # crop idx\n",
        "      idx_crop = idx[:, -conf.block_size:]\n",
        "      # new predication\n",
        "      logits, _ = self(idx_crop)\n",
        "      # last time stamp\n",
        "      logits = logits[:,-1,:] # B, C\n",
        "      # softmax to get probabilities\n",
        "      probs = F.softmax(logits, dim=-1) # B, C\n",
        "      # draw sample from disribution\n",
        "      idx_next = torch.multinomial(probs, num_samples=1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "mZfF7vB0otIO"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance of model\n",
        "model = AttentionNeuralNetwork()\n",
        "model.to(conf.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU5z_l6VqMNg",
        "outputId": "f23a381c-5a69-4c96-97e8-7fbb66e2b7d5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionNeuralNetwork(\n",
              "  (token_embeding_table): Embedding(65, 384)\n",
              "  (position_embeding_table): Embedding(256, 384)\n",
              "  (blocks): Sequential(\n",
              "    (0): AttentionBlock(\n",
              "      (layer_norm_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (fd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): AttentionBlock(\n",
              "      (layer_norm_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (fd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): AttentionBlock(\n",
              "      (layer_norm_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (fd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): AttentionBlock(\n",
              "      (layer_norm_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (fd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): AttentionBlock(\n",
              "      (layer_norm_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (fd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): AttentionBlock(\n",
              "      (layer_norm_1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm_2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (sa_head): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (fd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=384, out_features=65, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Put model in train mode\n",
        "model.train()\n",
        "\n",
        "# Train model\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=conf.learning_rate)\n",
        "\n",
        "# Train model for maximum number of batches\n",
        "for iter_i in range(conf.number_iterations):\n",
        "  # Every once evaluate train and eval dataset loss\n",
        "  if iter_i % conf.eval_interval == 0:\n",
        "    evaluation = estimate_loss()\n",
        "    print('Step {}: Train loss {:.3f}, Eval loss {:.3f}'.format(\n",
        "                                                    iter_i,\n",
        "                                                    evaluation['train'],\n",
        "                                                    evaluation['eval']))\n",
        "  # Train the model with one mini-batch\n",
        "  X, y_true = get_batch(split_name='train')\n",
        "  logits, loss = model(X, y_true)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "7S5oIB-JFpXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0bf8c5-3077-439a-90aa-84a9319e6ff2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: Train loss 4.273, Eval loss 4.271\n",
            "Step 500: Train loss 2.009, Eval loss 2.096\n",
            "Step 1000: Train loss 1.606, Eval loss 1.779\n",
            "Step 1500: Train loss 1.439, Eval loss 1.640\n",
            "Step 2000: Train loss 1.340, Eval loss 1.571\n",
            "Step 2500: Train loss 1.280, Eval loss 1.538\n",
            "Step 3000: Train loss 1.226, Eval loss 1.506\n",
            "Step 3500: Train loss 1.181, Eval loss 1.487\n",
            "Step 4000: Train loss 1.146, Eval loss 1.484\n",
            "Step 4500: Train loss 1.110, Eval loss 1.478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a sample\n",
        "idx = torch.zeros((1, 1), dtype=torch.long, device=conf.device)\n",
        "print(decode(model.generate(idx, max_new_tokens=1500)[0].tolist()))"
      ],
      "metadata": {
        "id": "T1jDk1GxJD_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15839f4-208d-4439-c812-58b93c7f62ca"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Upweak ta'en their covery souls, with the king:\n",
            "Boy. Better than I say, Clarence' come.\n",
            "\n",
            "ABHORSON:\n",
            "What should the Capulet's daughter? Dost thou?\n",
            "\n",
            "SOMERSET:\n",
            "Marry, sir, no man stop to her.\n",
            "\n",
            "HORTENSIO:\n",
            "One poor Romeo more son, and be a\n",
            "balefant words in the things. O, sir, I am respected\n",
            "more with him and friendship of a tyrant!\n",
            "\n",
            "TYRREL:\n",
            "O, think you shall not dream,\n",
            "Whose treason seven sons should be so in man's\n",
            "Shall dispose the seas, and like even false with me\n",
            "I betray my adversed pluck my foot: then yet I\n",
            "In sister what I plainly was while as smuch as\n",
            "You shall.\n",
            "\n",
            "GLOUCESTER:\n",
            "I would it go against your cousin; and I was\n",
            "Against your body or in the leisure of youth:\n",
            "Is it thou remembran not to begetter thy flight?\n",
            "I will but a scolding friend\n",
            "Thee, uncle you and forswear to beging this Katham,\n",
            "Why stoling you look'd by him met a command.\n",
            "O many is her protectors?\n",
            "'Tis subound to save: we cannot know her, my lord,\n",
            "I shall be certain'd to my hope.\n",
            "How now! What, yea present your honour\n"
          ]
        }
      ]
    }
  ]
}